_**Описание проекта:** Компания онлайн-сервиса с высоким уровнем входящего трафика имеет специализированный отдел безопасности, который занимается фильтрацией и анализом трафика. Сотрудники этого отдела обратились за помощью в автоматизации выявления аномального и злонамеренного трафика. Задача - разработать модель, которая будет классифицировать трафик на нормальный и злонамеренный, включая следующие типы атак: DDoS, SQL-инъекции, брутфорс, вредоносные программы и т.д._

_**Цель проекта:** разработать модель для определения типа входящего трафика: нормальный или злонамеренный. Добиться максимального значения метрик качества **precision, recall, f1_score, accuracy**._

_**Входные данные:** Заказчиком предоставлен файл в формате csv с различными параметрами входящего трафика (~540 000 строк)._

_**Что было сделано:** Исследование данных проводилосьс помощью **EDA** (Exploratory Data Analysis- разведочный анализ данных) с использованием следующих библиотек для Python: **numpy, pandas, seaborn, matplotlib**. Предобработка данных осуществлялась средствами библиотек для **Python: pandas, numpy, scikit-learn.** Перед проектированием модели была произведена очистка данных, заполнение пропусков, масштабирование численных признаков. В качестве baseline моделей изначально были обучены методом кросс-валидации: **LogisticRegression(), RandomForestClassifier(), LGBMClassifier().** Из них были выбраны две: простая **RandomForestClassifier()** и бустинговая **LGBMClassifier(),** которые участвовали в последующем переобучении (LGBMClassifier() обучена также с подбором гиперпараметров при помощи библиотеки **Optuna**). Оценка качества моделей машинного обучения производилась метрикой accuracy и **classification_report** на тестовом наборе, выделенного из основного в размере 20% от всех данных. В ходе работы над проектом был сгенерирован дополнительный признак для обучающего набора, а также клонированы малочисленные классы целевого признака. Это позволило улучшить метрику на кросс-валидации (на обучающем) у **LGBMClassifier с 89.0188% до 99.9998%,** у **RandomForestClassifier c 99.7408% до 99.9888%.** На тестовом наборе **LGBMClassifier** сработала с точностью **99.8795%**. Модель сохранена для последующего использования с сервисом **Flask**._

_**Навыки и инструменты: Python, Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, LightGBM, Optuna.**_

 [Смотреть Jupyter Notebook](https://github.com/fortuna26/Data_Science_Projects/blob/main/information_security/information_security.ipynb)|

------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------

_Комментарии после ревью:_
После ревью работа была переделана полностью, но добиться таких результатов не удалось. Хочу отметить, что использование метрики accuracy было излишним и ошибочным. **Classification report** в рамках многоклассовой целевой переменной подходит идеально.
В новом варианте исследования были проведены такие манипуляции с данными как удаление дубликатов, удаление коррелирующих признаков, исправление аномальных отрицательных значений в признаках на медианные. Для борьбы с дисбалансом классов была применена передискретизация с использованием **SMOTE** и очистки ссылок **Tomek** (библиотека imbalanced-learn). Но это не позволило добиться высоких метрик, т.е.например всех 1 по precision/recall/f1 у всех классов как у модели RandomForestClassifier() или LGBMClassifier(). Особенно проседала метрика при удалении имеющихся дубликатов и отказа от прямого дублирования данных. Тем не менее эти манипуляции улучшили метрики по сравнению с полученными первоначально от бэйзлайн-моделей.

 [Смотреть другой Jupyter Notebook](https://github.com/fortuna26/Yandex_Practicum/tree/main/Games)|
